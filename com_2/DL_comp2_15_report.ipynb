{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Object Detection\n",
    "\n",
    "### 107062514 賴鵬仁\n",
    "### 107062616 傅品捷\n",
    "### 107065513 姚定嘉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file = open(\"./pascal_voc_training_data.txt\", \"r\")\n",
    "for i, line in enumerate(training_data_file):\n",
    "    if i >5:\n",
    "        break\n",
    "    line = line.strip()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "#if you have multiple GPU on the machine, choose only one to use on this notebook\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#let the gpu allocates memory space dynamically\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRunner:\n",
    "    \"\"\"\n",
    "    Load pascalVOC 2007 dataset and creates an input pipeline ready to be fed into a model.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, common_params, dataset_params):\n",
    "        \n",
    "        self.width = common_params['image_size']\n",
    "        self.height = common_params['image_size']\n",
    "        self.batch_size = common_params['batch_size']\n",
    "        self.num_classes = common_params['num_classes']\n",
    "        self.data_path = dataset_params['path']\n",
    "        self.thread_num = dataset_params['thread_num']\n",
    "        self.image_dir = dataset_params['image_dir']\n",
    "        \n",
    "        self.max_objects = common_params['max_objects_per_image']\n",
    "            \n",
    "        self.graph = tf.Graph()\n",
    "        self.sess = tf.Session(graph=self.graph, config=config)\n",
    "        \n",
    "        self.image_names = []\n",
    "        self.record_list = []\n",
    "        self.object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(self.data_path, 'r')\n",
    "        \n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            self.image_names.append(ss[0])\n",
    "\n",
    "            self.record_list.append([float(num) for num in ss[1:]])\n",
    "            \n",
    "            self.object_num_list.append(min(len(self.record_list[-1])//5, self.max_objects))\n",
    "            if len(self.record_list[-1])<self.max_objects*5:\n",
    "                self.record_list[-1] = self.record_list[-1] +\\\n",
    "                [float(0), float(0), float(0), float(0), float(0)]*\\\n",
    "                (self.max_objects-len(self.record_list[-1])//5)\n",
    "                \n",
    "            elif len(self.record_list[-1])>self.max_objects*5:\n",
    "                self.record_list[-1] = self.record_list[-1][:self.max_objects*5]\n",
    "\n",
    "        self.build_train_data_tensor()\n",
    "            \n",
    "    def build_train_data_tensor(self):\n",
    "        \n",
    "        def data_generator(image_name, raw_labels, object_num):\n",
    "            image_file = tf.read_file(self.image_dir+image_name)\n",
    "            image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "            h = tf.shape(image)[0]\n",
    "            w = tf.shape(image)[1]\n",
    "\n",
    "            width_rate = self.width * 1.0 / tf.cast(w, tf.float32) \n",
    "            height_rate = self.height * 1.0 / tf.cast(h, tf.float32) \n",
    "\n",
    "            image = tf.image.resize_images(image, size=[self.height,self.width])\n",
    "            \n",
    "            raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "            \n",
    "            xmin = raw_labels[:, 0]\n",
    "            ymin = raw_labels[:, 1]\n",
    "            xmax = raw_labels[:, 2]\n",
    "            ymax = raw_labels[:, 3]\n",
    "            class_num = raw_labels[:, 4]\n",
    "            \n",
    "            xcenter = (xmin + xmax) * 1.0 / 2.0 * width_rate\n",
    "            ycenter = (ymin + ymax) * 1.0 / 2.0 * height_rate\n",
    "            \n",
    "            box_w = (xmax - xmin) * width_rate\n",
    "            box_h = (ymax - ymin) * height_rate\n",
    "            \n",
    "            labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis = 1)\n",
    "\n",
    "            return image, labels, tf.cast(object_num, tf.int32)\n",
    "            \n",
    "\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            dataset = tf.data.Dataset.from_tensor_slices((self.image_names, \n",
    "                                                          np.array(self.record_list), \n",
    "                                                          np.array(self.object_num_list)))\n",
    "\n",
    "            dataset = dataset.map(data_generator, num_parallel_calls = self.thread_num)\n",
    "            dataset = dataset.shuffle(len(record_list))\n",
    "            dataset = dataset.batch(self.batch_size)\n",
    "            dataset = dataset.repeat()\n",
    "\n",
    "            self.iterator = tf.data.Iterator.from_structure(dataset.output_types)  \n",
    "            self.data_init_op = self.iterator.make_initializer(dataset)\n",
    "\n",
    "            self.sess.run(self.data_init_op)\n",
    "            self.iterate_op = self.iterator.get_next()\n",
    "            \n",
    "    def batch(self):\n",
    "        images, labels, objects_num = self.sess.run(self.iterate_op)\n",
    "\n",
    "        if objects_num.shape[0] < self.batch_size:\n",
    "            images, labels, objects_num = self.sess.run(self.iterate_op)\n",
    "        \n",
    "        images = images/255 * 2 - 1\n",
    "        \n",
    "        return images, labels, objects_num\n",
    "        \n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "    def close(self):\n",
    "\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一開始train 出來的model在training data 的表現是可行的，但是在testing data  表現卻非常糟糕。所以我們猜測是overfitting的問題，為了增進generalizability，我們嘗試使用data augmentation ，照著Lab12-1的notebook做distort。最後出來的結果也沒改進多少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Model (YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloTinyNet(object):\n",
    "\n",
    "    def __init__(self, common_params, net_params, test=False):\n",
    "        \"\"\"\n",
    "        common params: a params dict\n",
    "        net_params   : a params dict\n",
    "        \"\"\"\n",
    "        #pretrained variable collection\n",
    "        self.pretrained_collection = []\n",
    "        #trainable variable collection\n",
    "        self.trainable_collection = []\n",
    "         \n",
    "        #process params\n",
    "        self.image_size = int(common_params['image_size'])\n",
    "        self.num_classes = int(common_params['num_classes'])\n",
    "        self.cell_size = int(net_params['cell_size'])\n",
    "        self.boxes_per_cell = int(net_params['boxes_per_cell'])\n",
    "        self.batch_size = int(common_params['batch_size'])\n",
    "        self.weight_decay = float(net_params['weight_decay'])\n",
    "\n",
    "        if not test:\n",
    "            self.object_scale = float(net_params['object_scale'])\n",
    "            self.noobject_scale = float(net_params['noobject_scale'])\n",
    "            self.class_scale = float(net_params['class_scale'])\n",
    "            self.coord_scale = float(net_params['coord_scale'])\n",
    "         \n",
    "    def _variable_on_cpu(self, name, shape, initializer, pretrain=True, train=True):\n",
    "        \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "        Args:\n",
    "          name: name of the Variable\n",
    "          shape: list of ints\n",
    "          initializer: initializer of Variable\n",
    "        Returns:\n",
    "          Variable Tensor\n",
    "        \"\"\"\n",
    "        with tf.device('/cpu:0'):\n",
    "            var = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "            if pretrain:\n",
    "                self.pretrained_collection.append(var)\n",
    "            if train:\n",
    "                self.trainable_collection.append(var)\n",
    "        return var \n",
    "    \n",
    "    def _variable_with_weight_decay(self, name, shape, stddev, wd, pretrain=True, train=True):\n",
    "        \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "        Note that the Variable is initialized with truncated normal distribution\n",
    "        A weight decay is added only if one is specified.\n",
    "        Args:\n",
    "          name: name of the variable \n",
    "          shape: list of ints\n",
    "          stddev: standard devision of a truncated Gaussian\n",
    "          wd: add L2Loss weight decay multiplied by this float. If None, weight \n",
    "          decay is not added for this Variable.\n",
    "       Returns:\n",
    "          Variable Tensor \n",
    "        \"\"\"\n",
    "        var = self._variable_on_cpu(name, shape,\n",
    "            tf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32), pretrain, train)\n",
    "        if wd is not None:\n",
    "            weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "            tf.add_to_collection('losses', weight_decay)\n",
    "        return var \n",
    "\n",
    "    \n",
    "    \n",
    "    def conv2d(self, scope, input, kernel_size, stride=1, pretrain=True, train=True):\n",
    "\n",
    "        with tf.variable_scope(scope) as scope:\n",
    "            kernel = self._variable_with_weight_decay('weights', \n",
    "                                      shape=kernel_size,\n",
    "                                      stddev=5e-2,\n",
    "                                      wd=self.weight_decay, pretrain=pretrain, train=train)\n",
    "            conv = tf.nn.conv2d(input, kernel, [1, stride, stride, 1], padding='SAME')\n",
    "            biases = self._variable_on_cpu('biases', kernel_size[3:], tf.constant_initializer(0.0), pretrain, train)\n",
    "            bias = tf.nn.bias_add(conv, biases)\n",
    "            conv1 = self.leaky_relu(bias)\n",
    "\n",
    "        return conv1    \n",
    "    def max_pool(self, input, kernel_size, stride):\n",
    "\n",
    "        return tf.nn.max_pool(input, ksize=[1, kernel_size[0], kernel_size[1], 1], strides=[1, stride, stride, 1],\n",
    "                  padding='SAME')\n",
    "    \n",
    "    def fully(self, scope, input, in_dimension, out_dimension, leaky=True, pretrain=True, train=True):\n",
    "        \"\"\"Fully connection layer\n",
    "        Args:\n",
    "          scope: variable_scope name\n",
    "          input: [batch_size, ???]\n",
    "          out_dimension: int32\n",
    "        Return:\n",
    "          output: 2-D tensor [batch_size, out_dimension]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(scope) as scope:\n",
    "            reshape = tf.reshape(input, [tf.shape(input)[0], -1])\n",
    "            #print(reshape.shape)\n",
    "            weights = self._variable_with_weight_decay('weights', shape=[in_dimension, out_dimension],\n",
    "                                  stddev=0.04, wd=self.weight_decay, pretrain=pretrain, train=train)\n",
    "            #print(weights.shape)\n",
    "            biases = self._variable_on_cpu('biases', [out_dimension], tf.constant_initializer(0.0), pretrain, train)\n",
    "            local = tf.matmul(reshape, weights) + biases\n",
    "\n",
    "            if leaky:\n",
    "                local = self.leaky_relu(local)\n",
    "            else:\n",
    "                local = tf.identity(local, name=scope.name)\n",
    "\n",
    "        return local\n",
    "    \n",
    "    def leaky_relu(self, x, alpha=0.1, dtype=tf.float32):\n",
    "        \"\"\"leaky relu \n",
    "        if x > 0:\n",
    "          return x\n",
    "        else:\n",
    "          return alpha * x\n",
    "        Args:\n",
    "          x : Tensor\n",
    "          alpha: float, the slope of the leaky function\n",
    "        Return:\n",
    "          y : Tensor\n",
    "        \"\"\"\n",
    "        x = tf.cast(x, dtype=dtype)\n",
    "        \n",
    "        return tf.nn.leaky_relu(x, alpha=alpha)\n",
    "    \n",
    "    def inference(self, images):\n",
    "        \"\"\"Build the yolo model\n",
    "        Input the images, output prediction boxes(center_x, center_y, w, h, scale) and the corresponding classes\n",
    "        \n",
    "        Args:\n",
    "          images:  4-D tensor [batch_size, image_height, image_width, channels]\n",
    "        Returns:\n",
    "          predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "        \"\"\"\n",
    "        #images = tf.reshape(images, [-1, self.image_size*self.image_size*3])\n",
    "        conv1 = self.conv2d('conv1', images, [3, 3, 3, 16], stride=1)\n",
    "\n",
    "        pool1 = self.max_pool(conv1, [2, 2], 2)\n",
    "\n",
    "        conv2 = self.conv2d('conv2', pool1, [3, 3, 16, 32], stride=1)\n",
    "\n",
    "        pool2 = self.max_pool(conv2, [2, 2], 2)\n",
    "\n",
    "        conv3 = self.conv2d('conv3', pool2, [3, 3, 32, 64], stride=1)\n",
    "    \n",
    "        pool3 = self.max_pool(conv3, [2, 2], 2)\n",
    "\n",
    "        conv4 = self.conv2d('conv4', pool3, [3, 3, 64, 128], stride=1)\n",
    "\n",
    "        pool4 = self.max_pool(conv4, [2, 2], 2)\n",
    "\n",
    "        conv5 = self.conv2d('conv5', pool4, [3, 3, 128, 256], stride=1)\n",
    "\n",
    "        pool5 = self.max_pool(conv5, [2, 2], 2)\n",
    "\n",
    "        conv6 = self.conv2d('conv6', pool5, [3, 3, 256, 512], stride=1)\n",
    "\n",
    "        pool6 = self.max_pool(conv6, [2, 2], 2)\n",
    "\n",
    "        conv7 = self.conv2d('conv7', pool6, [3, 3, 512, 1024], stride=1)   \n",
    "\n",
    "        conv8 = self.conv2d('conv8', conv7, [3, 3, 1024, 1024], stride=1) \n",
    "\n",
    "        conv9 = self.conv2d('conv9', conv8, [3, 3, 1024, 1024], stride=1)\n",
    "\n",
    "        temp_conv = tf.transpose(conv9, (0, 3, 1, 2))\n",
    "            \n",
    "        \n",
    "        fully1 = self.fully('fully1', temp_conv, 7 * 7 * 1024, 256)\n",
    "\n",
    "        fully2 = self.fully('fully2', fully1, 256, 4096)\n",
    "        \n",
    "        drop1 = tf.nn.dropout(fully2, keep_prob=0.5)\n",
    "\n",
    "        fully3 = self.fully('fully3', drop1, 4096, self.cell_size * self.cell_size * \n",
    "                            (self.num_classes + self.boxes_per_cell * 5), leaky=False,\n",
    "                            pretrain=False, train=True)\n",
    "\n",
    "        n1 = self.cell_size * self.cell_size * self.num_classes\n",
    "\n",
    "        n2 = n1 + self.cell_size * self.cell_size * self.boxes_per_cell\n",
    "\n",
    "        class_probs = tf.reshape(fully3[:, 0:n1], (-1, self.cell_size, self.cell_size, self.num_classes))\n",
    "        scales = tf.reshape(fully3[:, n1:n2], (-1, self.cell_size, self.cell_size, self.boxes_per_cell))\n",
    "        boxes = tf.reshape(fully3[:, n2:], (-1, self.cell_size, self.cell_size, self.boxes_per_cell * 4))\n",
    "\n",
    "        predicts = tf.concat([class_probs, scales, boxes], 3)\n",
    "\n",
    "        return predicts\n",
    "\n",
    "    def iou(self, boxes1, boxes2):\n",
    "        \"\"\"calculate ious\n",
    "        Args:\n",
    "          boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "          boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "          \n",
    "        Return:\n",
    "          iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        \"\"\"\n",
    "        \n",
    "        #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "        boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                          boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "        \n",
    "        #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "        boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "\n",
    "        boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                          boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "        #calculate the left up point of boxes' overlap area\n",
    "        lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "        #calculate the right down point of boxes overlap area\n",
    "        rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "        #intersection\n",
    "        intersection = rd - lu \n",
    "\n",
    "        #the size of the intersection area\n",
    "        inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "        \n",
    "        mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "        #if intersection is negative, then the boxes don't overlap\n",
    "        inter_square = mask * inter_square\n",
    "\n",
    "        #calculate the boxs1 square and boxs2 square\n",
    "        square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "        square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "        return inter_square/(square1 + square2 - inter_square + 1e-6)\n",
    "\n",
    "\n",
    "    def losses_calculation(self, num, object_num, loss, predict, labels, nilboy):\n",
    "        \"\"\"\n",
    "        calculate loss\n",
    "        Args:\n",
    "          predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "          labels : [max_objects, 5]  (x_center, y_center, w, h, class)\n",
    "        \"\"\"\n",
    "        label = labels[num:num+1, :]\n",
    "        label = tf.reshape(label, [-1])\n",
    "\n",
    "        #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "        min_x = (label[0] - label[2] / 2) / (self.image_size / self.cell_size)\n",
    "        max_x = (label[0] + label[2] / 2) / (self.image_size / self.cell_size)\n",
    "\n",
    "        min_y = (label[1] - label[3] / 2) / (self.image_size / self.cell_size)\n",
    "        max_y = (label[1] + label[3] / 2) / (self.image_size / self.cell_size)\n",
    "\n",
    "        min_x = tf.floor(min_x)\n",
    "        min_y = tf.floor(min_y)\n",
    "\n",
    "        max_x = tf.minimum(tf.ceil(max_x), self.cell_size)\n",
    "        max_y = tf.minimum(tf.ceil(max_y), self.cell_size)\n",
    "\n",
    "        temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "        objects = tf.ones(temp, tf.float32)\n",
    "\n",
    "        temp = tf.cast(tf.stack([min_y, self.cell_size - max_y, min_x, self.cell_size - max_x]), tf.int32)\n",
    "        temp = tf.reshape(temp, (2, 2))\n",
    "        objects = tf.pad(objects, temp, \"CONSTANT\")\n",
    "\n",
    "        #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "        #calculate responsible tensor [CELL_SIZE, CELL_SIZE]\n",
    "        center_x = label[0] / (self.image_size / self.cell_size)\n",
    "        center_x = tf.floor(center_x)\n",
    "\n",
    "        center_y = label[1] / (self.image_size / self.cell_size)\n",
    "        center_y = tf.floor(center_y)\n",
    "\n",
    "        response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "        temp = tf.cast(tf.stack([center_y, self.cell_size - center_y - 1, \n",
    "                                 center_x, self.cell_size -center_x - 1]), \n",
    "                       tf.int32)\n",
    "        self.tmp = tf.stack([center_y, self.cell_size - center_y - 1, \n",
    "                             center_x, self.cell_size -center_x - 1])\n",
    "        temp = tf.reshape(temp, (2, 2))\n",
    "        response = tf.pad(response, temp, \"CONSTANT\")\n",
    "        #objects = response\n",
    "\n",
    "        #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        predict_boxes = predict[:, :, self.num_classes + self.boxes_per_cell:]\n",
    "\n",
    "        predict_boxes = tf.reshape(predict_boxes, [self.cell_size, \n",
    "                                                   self.cell_size, \n",
    "                                                   self.boxes_per_cell, 4])\n",
    "\n",
    "        predict_boxes = predict_boxes * [self.image_size / self.cell_size, \n",
    "                                         self.image_size / self.cell_size, \n",
    "                                         self.image_size, self.image_size]\n",
    "\n",
    "        base_boxes = np.zeros([self.cell_size, self.cell_size, 4])\n",
    "\n",
    "        #for each cell\n",
    "        for y in range(self.cell_size):\n",
    "            for x in range(self.cell_size):\n",
    "                \n",
    "                base_boxes[y, x, :] = [self.image_size / self.cell_size * x, self.image_size / self.cell_size * y, 0, 0]\n",
    "                \n",
    "        base_boxes = np.tile(np.resize(base_boxes, [self.cell_size, self.cell_size, 1, 4]), [1, 1, self.boxes_per_cell, 1])\n",
    "\n",
    "        #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "        predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "        iou_predict_truth = self.iou(predict_boxes, label[0:4])\n",
    "        #calculate C [cell_size, cell_size, boxes_per_cell]\n",
    "        C = iou_predict_truth * tf.reshape(response, [self.cell_size, self.cell_size, 1])\n",
    "\n",
    "        #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        I = iou_predict_truth * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n",
    "\n",
    "        max_I = tf.reduce_max(I, 2, keep_dims=True)\n",
    "\n",
    "        I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n",
    "\n",
    "        #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        no_I = tf.ones_like(I, dtype=tf.float32) - I \n",
    "\n",
    "\n",
    "        p_C = predict[:, :, self.num_classes:self.num_classes + self.boxes_per_cell]\n",
    "\n",
    "        #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "        x = label[0]\n",
    "        y = label[1]\n",
    "\n",
    "        sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "        sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "\n",
    "        #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        p_x = predict_boxes[:, :, :, 0]\n",
    "        p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "        #p_sqrt_w = tf.sqrt(tf.abs(predict_boxes[:, :, :, 2])) * ((tf.cast(predict_boxes[:, :, :, 2] > 0, tf.float32) * 2) - 1)\n",
    "        #p_sqrt_h = tf.sqrt(tf.abs(predict_boxes[:, :, :, 3])) * ((tf.cast(predict_boxes[:, :, :, 3] > 0, tf.float32) * 2) - 1)\n",
    "        #p_sqrt_w = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 2]))\n",
    "        #p_sqrt_h = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 3]))\n",
    "        #p_sqrt_w = predict_boxes[:, :, :, 2]\n",
    "        #p_sqrt_h = predict_boxes[:, :, :, 3]\n",
    "        p_sqrt_w = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "        p_sqrt_h = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "        \n",
    "        #calculate truth p 1-D tensor [NUM_CLASSES]\n",
    "        P = tf.one_hot(tf.cast(label[4], tf.int32), self.num_classes, dtype=tf.float32)\n",
    "\n",
    "        #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "        p_P = predict[:, :, 0:self.num_classes]\n",
    "\n",
    "        #class_loss\n",
    "        class_loss = tf.nn.l2_loss(tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n",
    "        #class_loss = tf.nn.l2_loss(tf.reshape(response, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n",
    "\n",
    "        #object_loss\n",
    "        object_loss = tf.nn.l2_loss(I * (p_C - C)) * self.object_scale\n",
    "        #object_loss = tf.nn.l2_loss(I * (p_C - (C + 1.0)/2.0)) * self.object_scale\n",
    "\n",
    "        #noobject_loss\n",
    "        #noobject_loss = tf.nn.l2_loss(no_I * (p_C - C)) * self.noobject_scale\n",
    "        noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * self.noobject_scale\n",
    "\n",
    "        #coord_loss\n",
    "        coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(self.image_size/self.cell_size)) +\n",
    "                     tf.nn.l2_loss(I * (p_y - y)/(self.image_size/self.cell_size)) +\n",
    "                     tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ self.image_size +\n",
    "                     tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/self.image_size) * self.coord_scale\n",
    "\n",
    "        nilboy = I\n",
    "\n",
    "        return (num + 1, object_num, [loss[0] + class_loss, \n",
    "                                      loss[1] + object_loss, \n",
    "                                      loss[2] + noobject_loss,\n",
    "                                      loss[3] + coord_loss], \n",
    "                predict, labels, nilboy)\n",
    "\n",
    "    def loss(self, predicts, labels, objects_num):\n",
    "        \"\"\"Add Loss to all the trainable variables\n",
    "          Args:\n",
    "          predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\n",
    "          ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "          labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "          objects_num: 1-D tensor [batch_size]\n",
    "        \"\"\"\n",
    "        def condition(num, object_num, loss, predict, label, nilboy):\n",
    "            \"\"\"\n",
    "            if num < object_num\n",
    "            \"\"\"\n",
    "            return num < object_num\n",
    "        \n",
    "        class_loss = tf.constant(0, tf.float32)\n",
    "        object_loss = tf.constant(0, tf.float32)\n",
    "        noobject_loss = tf.constant(0, tf.float32)\n",
    "        coord_loss = tf.constant(0, tf.float32)\n",
    "        loss = [0, 0, 0, 0]\n",
    "        for i in range(self.batch_size):\n",
    "            predict = predicts[i, :, :, :]\n",
    "            label = labels[i, :, :]\n",
    "            object_num = objects_num[i]\n",
    "            nilboy = tf.ones([7,7,2])\n",
    "            tuple_results = tf.while_loop(condition, self.losses_calculation, \n",
    "                                          [tf.constant(0), object_num, \n",
    "                                           [class_loss, object_loss, noobject_loss, coord_loss], \n",
    "                                           predict, label, nilboy])\n",
    "\n",
    "            for j in range(4):\n",
    "                loss[j] = loss[j] + tuple_results[2][j]\n",
    "            nilboy = tuple_results[5]\n",
    "\n",
    "        tf.add_to_collection('losses', (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size)\n",
    "\n",
    "        tf.summary.scalar('class_loss', loss[0]/self.batch_size)\n",
    "        tf.summary.scalar('object_loss', loss[1]/self.batch_size)\n",
    "        tf.summary.scalar('noobject_loss', loss[2]/self.batch_size)\n",
    "        tf.summary.scalar('coord_loss', loss[3]/self.batch_size)\n",
    "        tf.summary.scalar('weight_loss', tf.add_n(tf.get_collection('losses')) \n",
    "                          - (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size )\n",
    "\n",
    "        return tf.add_n(tf.get_collection('losses'), name='total_loss'), nilboy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此把助教的fully 改成 conv + pooling。conv 和 pooling 的設計參照助教給的fully去改的，使用_variable_with_weight_decay去initialize kernel，使得weight能加進weight decay term，增進generalizability。我們翻閱了YOLO的論文，文中說明YOLO使用二十幾層的CNN，也提到另一種使用9層CNN的Fast YOLO，我們2種都嘗試過，二十幾層的效果比起9層的明顯差了許多，我們猜測是因為層數加深，導致overfitting更加嚴重所導致，所以最後我們使用9層CNN的架構，最後得到0.87~0.9之間的結果。因為overfitting仍然很嚴重，所以我們又嘗試在fully後面加上dropout改進，然而效果並沒有顯著的提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloRunner(object):\n",
    "\n",
    "    def __init__(self, dataset, net, common_params, solver_params):\n",
    "        #process params\n",
    "        self.learning_rate = float(solver_params['learning_rate'])\n",
    "        self.moment = float(solver_params['moment'])\n",
    "        self.batch_size = int(common_params['batch_size'])\n",
    "        self.height = int(common_params['image_size'])\n",
    "        self.width = int(common_params['image_size'])\n",
    "        self.max_objects = int(common_params['max_objects_per_image'])\n",
    "        self.train_dir = str(solver_params['train_dir'])\n",
    "        \n",
    "        if not os.path.exists(self.train_dir):\n",
    "            os.makedirs(self.train_dir)\n",
    "        \n",
    "        self.max_iterators = int(solver_params['max_iterators'])\n",
    "        self.print_frequency = int(solver_params['print_frequency'])\n",
    "        self.save_frequency = int(solver_params['save_frequency'])\n",
    "        #\n",
    "        self.dataset = dataset\n",
    "        self.net = net\n",
    "        #construct graph\n",
    "        self.construct_graph()\n",
    "    def _train(self):\n",
    "        \"\"\"Train model\n",
    "        Create an optimizer and apply to all trainable variables.\n",
    "        Args:\n",
    "          total_loss: Total loss from net.loss()\n",
    "          global_step: Integer Variable counting the number of training steps\n",
    "          processed\n",
    "        Returns:\n",
    "          train_op: op for training\n",
    "        \"\"\"\n",
    "        opt = tf.train.AdamOptimizer(self.learning_rate,)\n",
    "        grads = opt.compute_gradients(self.total_loss)\n",
    "\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=self.global_step)\n",
    "\n",
    "        return apply_gradient_op\n",
    "\n",
    "    def construct_graph(self):\n",
    "        # construct graph\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        self.images = tf.placeholder(tf.float32, (None, self.height, self.width, 3))\n",
    "        self.labels = tf.placeholder(tf.float32, (None, self.max_objects, 5))\n",
    "        self.objects_num = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "        self.predicts = self.net.inference(self.images)\n",
    "        self.total_loss, self.nilboy = self.net.loss(self.predicts, self.labels, self.objects_num)\n",
    "        tf.summary.scalar('loss', self.total_loss)\n",
    "        self.train_op = self._train()\n",
    "\n",
    "    def run(self):\n",
    "        saver = tf.train.Saver(self.net.trainable_collection, write_version=tf.train.SaverDef.V2)\n",
    "\n",
    "        init =  tf.global_variables_initializer()\n",
    "\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        sess = tf.Session(config = config)\n",
    "\n",
    "        sess.run(init)\n",
    "        \n",
    "        summary_writer = tf.summary.FileWriter(self.train_dir, sess.graph)\n",
    "\n",
    "        for step in range(self.max_iterators):\n",
    "            start_time = time.time()\n",
    "\n",
    "            np_images, np_labels, np_objects_num = self.dataset.batch()\n",
    "\n",
    "            _, loss_value, nilboy= sess.run([self.train_op, self.total_loss, self.nilboy], \n",
    "                                            feed_dict={self.images: np_images, \n",
    "                                                       self.labels: np_labels,\n",
    "                                                       self.objects_num: np_objects_num})\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "            if step % self.print_frequency== 0:\n",
    "                num_examples_per_step = self.dataset.batch_size\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = float(duration)\n",
    "\n",
    "                format_str = ('step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                              'sec/batch)')\n",
    "                print (format_str % (step, loss_value,\n",
    "                                     examples_per_sec, sec_per_batch))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "            if step % self.print_frequency == 0:\n",
    "                summary_str = sess.run(summary_op, feed_dict={self.images: np_images, \n",
    "                                                              self.labels: np_labels, \n",
    "                                                              self.objects_num: np_objects_num})\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "            if step % self.save_frequency == 0:\n",
    "                saver.save(sess, self.train_dir + '/model.ckpt', global_step=step)\n",
    "        sess.close()\n",
    "\n",
    "    def prepare_inference(self, model_version):\n",
    "        saver = tf.train.Saver(self.net.trainable_collection)\n",
    "        init =  tf.global_variables_initializer()\n",
    "        \n",
    "        self.sess = tf.Session(config = config)\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        saver.restore(self.sess, self.train_dir+'/model.ckpt-'+model_version)\n",
    "\n",
    "    def make_one_prediction(self, images):\n",
    "\n",
    "        prediction = self.sess.run(self.predicts, feed_dict= {self.images: images})\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們把助教的MomentumOptimizer改成AdamOptimizer，並把learning rate 0.000001改成0.0002。並把image size 改成 448 * 448 ，讓解析度比較高，期望得到比較好的accuaracy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    'image_size': 448,\n",
    "    'batch_size': 16,\n",
    "    'num_classes': 20,\n",
    "    'max_objects_per_image': 20\n",
    "}\n",
    "dataset_params = {\n",
    "    'path': 'pascal_voc_training_data.txt',\n",
    "    'image_dir': './VOCdevkit_train/VOC2007/JPEGImages/',\n",
    "    'thread_num': 5\n",
    "}\n",
    "net_params = {\n",
    "    'weight_decay': 0.0005,\n",
    "    'cell_size': 7,\n",
    "    'boxes_per_cell': 2,\n",
    "    'object_scale': 1,\n",
    "    'noobject_scale': 0.5,\n",
    "    'class_scale': 1,\n",
    "    'coord_scale': 5, \n",
    "\n",
    "}\n",
    "solver_params = {\n",
    "    'learning_rate': 0.0002,\n",
    "    'moment': 0.9,\n",
    "    'max_iterators': 30000,\n",
    "    'print_frequency': 100,\n",
    "    'save_frequency' : 100,\n",
    "    'train_dir': 'models2/yolo-like'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sys.path.append('./')\n",
    "\n",
    "dataset = DatasetRunner(common_params, dataset_params)\n",
    "net = YoloTinyNet(common_params, net_params)\n",
    "model_runner = YoloRunner(dataset, net, common_params, solver_params)\n",
    "\n",
    "model_runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predicts(resized_img, predicts):\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (7, 7, 1, 20))\n",
    "    C = np.reshape(C, (7, 7, 2, 1))\n",
    "        \n",
    "    P = C * p_classes\n",
    "    #print(P[4, 5, 1, :])\n",
    "    max_conf = np.max(P)\n",
    "\n",
    "    thresh = 0.12  # threshold to select detection result\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            temp_data = np.zeros_like(P, np.float32)\n",
    "            temp_data[i, j, :, :] = P[i, j, :, :]\n",
    "            position = np.argmax(temp_data)\n",
    "            index = np.unravel_index(position, P.shape)\n",
    "            if P[index] > thresh:\n",
    "                class_num = index[3]\n",
    "\n",
    "                coordinate = np.reshape(coordinate, (7, 7, 2, 4))\n",
    "\n",
    "                max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "                xcenter = max_coordinate[0]\n",
    "                ycenter = max_coordinate[1]\n",
    "                w = max_coordinate[2]\n",
    "                h = max_coordinate[3]\n",
    "\n",
    "                xcenter = (index[1] + xcenter) * (448 / 7.0)\n",
    "                ycenter = (index[0] + ycenter) * (448 / 7.0)\n",
    "\n",
    "                w = w * 448\n",
    "                h = h * 448\n",
    "\n",
    "                # handle index out range problem\n",
    "                xmin = 0 if (xcenter - w / 2.0 < 0) else (xcenter - w / 2.0)\n",
    "                ymin = 0 if (ycenter - h / 2.0 < 0) else (ycenter - h / 2.0)\n",
    "                xmax = resized_img.shape[0] if (xmin + w > resized_img.shape[0]) else (xmin + w)\n",
    "                ymax = resized_img.shape[1] if (ymin + h > resized_img.shape[1]) else (ymin + h)\n",
    "\n",
    "                class_name = classes_name[class_num]\n",
    "                cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255))\n",
    "                cv2.putText(resized_img, class_name, (int(xmin), int(ymin)), 2, 1.5, (0, 0, 255))\n",
    "    processed_image = resized_img\n",
    "    return processed_image\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    index = np.argmax(P)\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "    class_num = index[3]\n",
    "\n",
    "    coordinate = np.reshape(coordinate, (7, 7, 2, 4))\n",
    "\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "\n",
    "    xcenter = (index[1] + xcenter) * (448/7.0)\n",
    "    ycenter = (index[0] + ycenter) * (448/7.0)\n",
    "\n",
    "    w = w * 448\n",
    "    h = h * 448\n",
    "\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    return xmin, ymin, xmax, ymax, class_num , max_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "common_params['batch_size'] = 1\n",
    "net = YoloTinyNet(common_params, net_params)\n",
    "solver = YoloRunner(None, net, common_params, solver_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = open('pascal_voc_testing_data.txt')\n",
    "test_img_dir = './VOCdevkit_test/VOC2007/JPEGImages/'\n",
    "test_images = []\n",
    "img_size = common_params['image_size']\n",
    "\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(ss[0])\n",
    "    \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "def load_img_data(image_name):\n",
    "    \n",
    "    image_file = tf.read_file(test_img_dir+image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "    \n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    image = tf.image.resize_images(image, size=[img_size,img_size])\n",
    "    \n",
    "    return image_name, image, h, w\n",
    "test_dataset = test_dataset.map(load_img_data)\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "next_test_element = test_iterator.get_next()\n",
    "tdata_sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, './evaluate')\n",
    "import evaluate\n",
    "#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\n",
    "evaluate.evaluate('./test_predion.txt', './submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('./test_predion.txt', 'w')\n",
    "solver.prepare_inference(model_version = '24100')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        img_name, test_img, img_h, img_w = tdata_sess.run(next_test_element)\n",
    "        test_img = test_img/255 * 2 - 1\n",
    "        test_img = np.reshape(test_img, (1, 448, 448, 3))\n",
    "        y_pred = solver.make_one_prediction(test_img)\n",
    "        xmin, ymin, xmax, ymax, class_num, conf = process_predicts(test_img,y_pred)\n",
    "\n",
    "        #xmin, ymin, xmax, ymax = xmin*(img_w/img_size), ymin*(img_h/img_size), xmax*(img_w/img_size), ymax*(img_h/img_size)\n",
    "\n",
    "        #img filename, (xmin, ymin, xmax, ymax, class, confidence)*number_of_predictions\n",
    "        output_file.write(img_name.decode('ascii')+\" %d %d %d %d %d %f\\n\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"done predicting all test data\")\n",
    "        break\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "np_img = cv2.imread('C:/Users/PinJJ/com_2/VOCdevkit_test/VOC2007/JPEGImages/000001.jpg')\n",
    "\n",
    "resized_img = cv2.resize(np_img, (common_params['image_size'], common_params['image_size']))\n",
    "np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "resized_img = np_img\n",
    "np_img = np_img.astype(np.float32)\n",
    "np_img = np_img / 255.0 * 2 - 1\n",
    "np_img = np.reshape(np_img, (1, common_params['image_size'], common_params['image_size'], 3))\n",
    "\n",
    "y_pred = solver.make_one_prediction(np_img)\n",
    "xmin, ymin, xmax, ymax, class_num, conf = process_predicts(y_pred)\n",
    "class_name = classes_name[class_num]\n",
    "cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 255), 3)\n",
    "cv2.putText(resized_img, class_name, (0, 200), 2, 1.5, (0, 255, 255), 2)\n",
    "plt.imshow(resized_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次的competition，我們發現除了model嚴重的overfit在training data之外，也發現model傾向把大部分的object都預測成person，我們嘗試了許多增進generalizability的方法，到最後還是沒有辦法讓結果得到顯著的提升。\n",
    "第一名也是用了yolo且沒有多做其他dataset的pretrain，聽完他的講解後，發現我們有許多細節沒有注意到。希望汲取他人經驗後，下次可以再進步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
